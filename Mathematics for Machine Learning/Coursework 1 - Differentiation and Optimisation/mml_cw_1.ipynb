{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursework 1: Gradient Descent (27 Points)\n",
    "### Autograding\n",
    "Part 1 of this coursework is autograded. This notebook comes with embedded tests which will verify that your implementations provide outputs with the appropriate types and shapes required for our hidden tests. You can run these same public tests through [LabTS](https://teaching.doc.ic.ac.uk/labts) when you have finished your work, to check that we get the same results when running these public tests.\n",
    "\n",
    "Hidden tests will be ran after the submission deadline, and cannot be accessed. They mostly check that you didn't cheat by using external functions, or that your implementations generate the correct answers for a few different (sensible) inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q otter-grader==4.1.0 numpy pandoc seaborn autograd memory-profiler graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization Cell\n",
    "%matplotlib inline\n",
    "import otter\n",
    "grader = otter.Notebook(\"mml_cw_1.ipynb\")\n",
    "import matplotlib.pyplot as plt # DO NOT use %matplotlib inline in the notebook\n",
    "import numpy as np\n",
    "rng_seed = 90"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 - Differentiation & Gradient Descent (16 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question, we define the following constants:\n",
    "\n",
    "$$\\boldsymbol{B}=\\left(\\begin{array}{cc}\n",
    "4 & -2 \\\\\n",
    "-2 & 4\n",
    "\\end{array}\\right), \\quad \\boldsymbol{a}=\\left(\\begin{array}{l}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{array}\\right), \\quad \\boldsymbol{b}=\\left(\\begin{array}{c}\n",
    "-2 \\\\\n",
    "1\n",
    "\\end{array}\\right)$$\n",
    "\n",
    "We define also the following functions, which are all $\\mathbb{R}^2 \\rightarrow \\mathbb{R}$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&f_1(\\boldsymbol{x})=\\boldsymbol{x}^T \\boldsymbol{B} \\boldsymbol{x}-\\boldsymbol{x}^T \\boldsymbol{x}+\\boldsymbol{a}^T \\boldsymbol{x}-\\boldsymbol{b}^T \\boldsymbol{x} \\\\\n",
    "&f_2(\\boldsymbol{x})=\\cos \\left((\\boldsymbol{x}-\\boldsymbol{b})^T(\\boldsymbol{x}-\\boldsymbol{b})\\right)+(\\boldsymbol{x}-\\boldsymbol{a})^T \\boldsymbol{B}(\\boldsymbol{x}-\\boldsymbol{a}) \\\\\n",
    "&f_3(\\boldsymbol{x})=1-\\left(\\exp \\left(-(\\boldsymbol{x}-\\boldsymbol{a})^T(\\boldsymbol{x}-\\boldsymbol{a})\\right)+\\exp \\left(-(\\boldsymbol{x}-\\boldsymbol{b})^T \\boldsymbol{B}(\\boldsymbol{x}-\\boldsymbol{b})\\right)-\\frac{1}{10} \\log \\left|\\frac{1}{100} \\boldsymbol{I}+\\boldsymbol{x} \\boldsymbol{x}^T\\right|\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "Implementations of these functions are provided below.\n",
    "\n",
    "Throughout this exercise, we remain consistent in our convention of using row vectors for our gradients $\\left( \\textnormal{i.e. } \\frac{\\partial f_1}{\\partial x}, \\frac{\\partial f_2}{\\partial x}, \\frac{\\partial f_3}{\\partial x} \\in \\mathbb{R}^{1 \\times 2} \\right )$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined constants\n",
    "B = np.array([[4, -2], [-2, 4]])\n",
    "a = np.array([[0], [1]])\n",
    "b = np.array([[-2], [1]])\n",
    "\n",
    "def f1(x):\n",
    "    \"\"\" Function f1 taking input x with shape (2, 1) \"\"\"\n",
    "    return float(x.T @ B @ x - x.T @ x + a.T @ x - b.T @ x)\n",
    "\n",
    "def f2(x):\n",
    "    \"\"\" Function f2 taking input x with shape (2, 1) \"\"\"\n",
    "    return float(np.cos((x - b).T @ (x - b)) + (x - a).T @ B @ (x - a))\n",
    "\n",
    "def f3(x):\n",
    "    \"\"\" Function f3 taking input x with shape (2, 1) \"\"\"\n",
    "    return float(1 - (np.exp(-(x - a).T @ (x - a)) + \\\n",
    "                 np.exp(-(x - b).T @ B @ (x - b)) - \\\n",
    "                 (1/10.) * np.log(np.linalg.det((1/100.) * np.identity(2) + x @ x.T))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 1 - Checking for the existence of Minima (2 Points)\n",
    "Complete the function ```f1_check_minimum(B, a, b)``` that checks whether function $f_1$ has a minimum given certain values of **a**, **b** and diagonal **B**.\n",
    "\n",
    "Hint: you may not need to use all three gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_check_minimum(B, a, b):\n",
    "    \"\"\" Write a function that returns True if function f1 has a minimum for variables B, a and b, and returns False otherwise.\n",
    "        Hint: it may not be required to use all B, a and b. \"\"\"\n",
    "    \n",
    "    #Existence condition of the extremum \n",
    "    extremum = B[0][0] != 1 and B[1][1] != 1\n",
    "    \n",
    "    #Calculation of the Hessian matrix and verification of the (positive) eigenvalues\n",
    "    if extremum == True:\n",
    "        hessian_matrix = np.array([[2*(B[0][0]-1), B[0][1] + B[1][1]], [B[0][1] + B[1][1],2*(B[1][1]-1)]])\n",
    "        eigenvalues = np.linalg.eigvals(hessian_matrix)\n",
    "        check_minimum = eigenvalues[0] > 0 and eigenvalues[1] > 0               \n",
    "    \n",
    "    return check_minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>1. Function 1 Minima Check</pre></strong> passed! ðŸ™Œ</p><p><strong><pre style='display: inline;'>1. Function 1 Minima Check - 1</pre> message:</strong> F1 Minimum Check (with minimum) Test Passed</p>"
      ],
      "text/plain": [
       "1. Function 1 Minima Check results: All test cases passed!\n",
       "1. Function 1 Minima Check - 1 message: F1 Minimum Check (with minimum) Test Passed"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"1. Function 1 Minima Check\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 2 - Calculating Gradients (6 Points)\n",
    "#### Question 2.a - Method of Finite Differences (2 Points)\n",
    "Remember (animation in lectures) that a gradient is found by taking\n",
    "$$ \\lim _{\\Delta x \\rightarrow 0} \\frac{f(x+\\Delta x)-f(x)}{\\Delta x} $$\n",
    "We can approximate this by calculating the expression for a small but finite $\\Delta x$ along each dimension, which\n",
    "is known as the _finite-differences_ approximation.\n",
    "\n",
    "Complete the function ```grad_fn(fn, x)``` such that it returns the gradients for any function ```fn``` at a point **x** using the method of finite differences. Use a delta of $1\\times 10^{-5}$.\n",
    "\n",
    "_The function should take a columnar numpy (2, 1) vector for â€˜xâ€™ as input, and output a\n",
    "numpy (1, 2) row vector for the gradient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grad_fd(fn, x, delta=1e-5):\n",
    "    \"\"\" General function that calculates gradient of some 2d function at point x,\n",
    "        using finite-differences.\n",
    "\n",
    "    Inputs:\n",
    "            fn: Function taking input x and returns a scalar\n",
    "            x: Numpy vector of shape (2, 1)\n",
    "            delta: Finite-difference delta (epsilon) used for approximation\n",
    "\n",
    "    Returns: Approximated gradient at point x, in shape (1, 2)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Delta vector and partial derivative w.r.t x1\n",
    "    delta_x1 = np.array([[delta],[0]])\n",
    "    dfdx1 = (fn(x + delta_x1) - fn(x))/delta\n",
    "    \n",
    "    #Delta vector and partial derivative w.r.t x2\n",
    "    delta_x2 = np.array([[0],[delta]])   \n",
    "    dfdx2 = (fn(x + delta_x2) - fn(x))/delta\n",
    "    \n",
    "    #Gradient vector\n",
    "    dfdx = np.array([[dfdx1, dfdx2]]) \n",
    "    \n",
    "    return dfdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>2.a Method of Finite Differences</pre></strong> passed! ðŸŒŸ</p><p><strong><pre style='display: inline;'>2.a Method of Finite Differences - 1</pre> message:</strong> Finite Differences on f1 Test Passed</p><p><strong><pre style='display: inline;'>2.a Method of Finite Differences - 2</pre> message:</strong> Finite Differences on f2 Test Passed</p>"
      ],
      "text/plain": [
       "2.a Method of Finite Differences results: All test cases passed!\n",
       "2.a Method of Finite Differences - 1 message: Finite Differences on f1 Test Passed\n",
       "2.a Method of Finite Differences - 2 message: Finite Differences on f2 Test Passed"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"2.a Method of Finite Differences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Question 2.b - Analytical Gradients (4 Points)\n",
    "Complete the functions ```f1_grad(x)```, ```f2_grad(x)``` and ```f3_grad(x)``` that return\n",
    "gradients of f1, f2 and f3, using your own derivations.\n",
    "\n",
    "_The functions should take a columnar numpy (2, 1) vector for **x** as input, and output a\n",
    "numpy (1, 2) row vector for the gradient_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f1_grad_exact(x):\n",
    "    \"\"\" Return gradient of f1, exactly derived by hand \"\"\"\n",
    "    \n",
    "    #We know B is symmetric so we can write 2 * x.T @ B. If B wasn't symmetric we should write x.T @ (B + B.T)\n",
    "    gradient = 2 * x.T @ B - 2 * x.T + a.T - b.T\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>Q2.b.i Gradients of the Functions - f1</pre></strong> passed! ðŸŒŸ</p><p><strong><pre style='display: inline;'>Q2.b.i Gradients of the Functions - f1 - 1</pre> message:</strong> Exact Gradients of f1 Test Passed</p>"
      ],
      "text/plain": [
       "Q2.b.i Gradients of the Functions - f1 results: All test cases passed!\n",
       "Q2.b.i Gradients of the Functions - f1 - 1 message: Exact Gradients of f1 Test Passed"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Q2.b.i Gradients of the Functions - f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f2_grad_exact(x):\n",
    "    \"\"\" Return gradient of f2, exactly derived by hand \"\"\"\n",
    "    \n",
    "    u = x - a\n",
    "    v = x - b\n",
    "    \n",
    "    #We know B is symmetric so we can write 2 * x.T @ B. If B wasn't symmetric we should write x.T @ (B + B.T)\n",
    "    gradient = -2 * v.T * np.sin(v.T @ v) + 2 * u.T @ B\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>Q2.b.ii Gradients of the Functions - f2</pre></strong> passed! ðŸ™Œ</p><p><strong><pre style='display: inline;'>Q2.b.ii Gradients of the Functions - f2 - 1</pre> message:</strong> Exact Gradients of f2 Test Passed</p>"
      ],
      "text/plain": [
       "Q2.b.ii Gradients of the Functions - f2 results: All test cases passed!\n",
       "Q2.b.ii Gradients of the Functions - f2 - 1 message: Exact Gradients of f2 Test Passed"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Q2.b.ii Gradients of the Functions - f2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f3_grad_exact(x):\n",
    "    \"\"\" Return gradient of f3, exactly derived by hand \"\"\"\n",
    "    \n",
    "    dlogdx = np.array([2*x[0,0] / (x[0,0]**2 + x[1,0]**2 + 1/100) , 2*x[1,0] / (x[0,0]**2 + x[1,0]**2 + 1/100)])\n",
    "    \n",
    "    u = x - a\n",
    "    v = x - b\n",
    "    \n",
    "    #We know B is symmetric so we can write 2 * x.T @ B. If B wasn't symmetric we should write x.T @ (B + B.T)\n",
    "    gradient = - ( -2 * u.T * np.exp(-u.T @ u) - 2 * v.T @ B * np.exp(-v.T @ B @ v) - (1/10) * dlogdx)\n",
    "    \n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>Q2.b.iii Gradients of the Functions - f3</pre></strong> passed! ðŸŒˆ</p><p><strong><pre style='display: inline;'>Q2.b.iii Gradients of the Functions - f3 - 1</pre> message:</strong> Exact Gradients of f2 Test Passed</p>"
      ],
      "text/plain": [
       "Q2.b.iii Gradients of the Functions - f3 results: All test cases passed!\n",
       "Q2.b.iii Gradients of the Functions - f3 - 1 message: Exact Gradients of f2 Test Passed"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Q2.b.iii Gradients of the Functions - f3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finite differencing method with f1 : [[-20.19997  42.80003]]\n",
      "Analytical gradient with f1 : [[-20.2  42.8]]\n",
      "Do we have the same results between the two methods? [[ True  True]]\n",
      "\n",
      "\n",
      "Finite differencing method with f2 : [[-20.28562387  40.43203696]]\n",
      "Analytical gradient with f2 : [[-20.2854567   40.43272319]]\n",
      "Do we have the same results between the two methods? [[ True  True]]\n",
      "\n",
      "\n",
      "Finite differencing method with f3 : [[0.00512269 0.0226476 ]]\n",
      "Analytical gradient with f3 : [[0.00512267 0.02264761]]\n",
      "Do we have the same results between the two methods? [[ True  True]]\n"
     ]
    }
   ],
   "source": [
    "# (optional) It's a good idea to test whether your analytical gradients \n",
    "# _closely_ match those given by finite differencing\n",
    "\n",
    "#Choosing random values for our x vector\n",
    "x1 = 1.9\n",
    "x2 = 8.4\n",
    "x = np.array([[x1],[x2]])\n",
    "\n",
    "print('Finite differencing method with f1 :', grad_fd(f1, x, delta=1e-5))\n",
    "print('Analytical gradient with f1 :', f1_grad_exact(x))\n",
    "print('Do we have the same results between the two methods?', np.round(grad_fd(f1, x, delta=1e-5),1) == np.round(f1_grad_exact(x),1))\n",
    "print('\\n')\n",
    "\n",
    "print('Finite differencing method with f2 :', grad_fd(f2, x, delta=1e-5))\n",
    "print('Analytical gradient with f2 :', f2_grad_exact(x))\n",
    "print('Do we have the same results between the two methods?', np.round(grad_fd(f2, x, delta=1e-5),1) == np.round(f2_grad_exact(x),1))\n",
    "print('\\n')\n",
    "\n",
    "print('Finite differencing method with f3 :', grad_fd(f3, x, delta=1e-5))\n",
    "print('Analytical gradient with f3 :', f3_grad_exact(x))\n",
    "print('Do we have the same results between the two methods?', np.round(grad_fd(f3, x, delta=1e-5),1) == np.round(f3_grad_exact(x),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 3 - Gradient Descent (8 Points)\n",
    "Use your gradients to implement a gradient descent algorithm **with 50 iterations**\n",
    "to find a local minimum for both f2 and f3, by finishing the function grad descent(fn,\n",
    "grad fn).\n",
    "\n",
    "For visualizing (and debugging) your gradient descent function, we provide some plotting code. This is contained in the cell below, so be sure to exectue it. You can use this function on f1 by passing in the other functions, for example: ```plot_grad_descent(f1, f1_grad_exact, gradient_descent)``` once you have completed the ```gradient_descent(fn, grad_fn)``` function. You can also pass in ```xrange=(x_min, x_max)``` and likewise for ```yrange``` to adjust the plotted region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide function for plotting gradient descent\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_grad_descent(fn, fn_grad, gradient_descent_fn, xrange=(-1, 1), yrange=(-1,1), **kwargs):\n",
    "    title = 'Plotting function #'+ fn_grad.__name__.split('_')[0][-1]\n",
    "    # Define plotting range for x- and y- axis.\n",
    "    x1min, x1max = xrange\n",
    "    x2min, x2max = yrange\n",
    "\n",
    "    # Evaluate function everywhere within the defined range for the contour plot\n",
    "    x1 = np.linspace(x1min, x1max, 100)\n",
    "    x2 = np.linspace(x2min, x2max, 100)\n",
    "\n",
    "    X1, X2 = np.meshgrid(x1, x2)\n",
    "\n",
    "    Y = [fn(np.array([[p1], [p2]])) for p1, p2 in zip(X1.flatten(), X2.flatten())]\n",
    "    Y = np.array(Y).reshape(X1.shape)\n",
    "\n",
    "    # Plot contour\n",
    "    plt.title(title)\n",
    "    plt.xlim(x1min, x1max)\n",
    "    plt.ylim(x2min, x2max)\n",
    "    plt.contourf(X1, X2, Y)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # Plot gradient descent trajectory\n",
    "    trajectory, found_minimum, found_minimum_value = gradient_descent_fn(fn, fn_grad, **kwargs)\n",
    "\n",
    "    p1, p2 = zip(*trajectory)\n",
    "    plt.plot(p1, p2, '.-', color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.a - Implementing Gradient Descent (4 Points)\n",
    "Complete the ```gradient_descent``` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(fn, grad_fn, start_x=4.0, start_y=4.0, lr=0.001, n_steps=50, silent=False):\n",
    "    \"\"\" Function that performs gradient descent.\n",
    "\n",
    "    Inputs: \n",
    "        - fn: Function to minimize\n",
    "        - grad_fn: Function that returns gradient of the function to minimize\n",
    "        - start_loc: Initial location\n",
    "        - lr: The learning rate\n",
    "        - n_steps: Number of steps\n",
    "        - silent: prevent print statement (for testing)\n",
    "\n",
    "    Returns: Tuple containing:\n",
    "        - trajectory of found points: a list containing numpy (2, 1) column vectors\n",
    "        - final minimum point: a numpy (2, 1) column vector\n",
    "        - the value at the minimum: float\n",
    "    \"\"\"\n",
    "\n",
    "    start_loc = np.array([[start_x], [start_y]])\n",
    "    trajectory = [start_loc]\n",
    "    lowest_value = np.inf\n",
    "        \n",
    "    for step in range(1,n_steps+1):\n",
    "        \n",
    "        #Calculation of the new position (thus the two coordinates)\n",
    "        new_x1_loc = start_loc[0] - lr * grad_fn(start_loc)[0][0]\n",
    "        new_x2_loc = start_loc[1] - lr * grad_fn(start_loc)[0][1]\n",
    "        \n",
    "        #Updating our location overtime\n",
    "        start_loc = np.array([[new_x1_loc[0]], [new_x2_loc[0]]])  \n",
    "\n",
    "        #Stocking all the positions and calculating the value at this precise new position\n",
    "        trajectory.append(start_loc)        \n",
    "        new_value = fn(trajectory[step])\n",
    "        \n",
    "        #Verification of the lowest value which equivalent to the last one (if our algorithm converges)\n",
    "        if new_value < lowest_value:\n",
    "            lowest_value = new_value\n",
    "            found_minimum_value = lowest_value\n",
    "            found_minimum_loc = start_loc\n",
    "\n",
    "    if not silent:\n",
    "        print(f\"Gradient descent found minimum value {found_minimum_value:.2f} at {found_minimum_loc.T}^T\")\n",
    "        \n",
    "    return trajectory, found_minimum_loc, found_minimum_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient descent found minimum value 8.37 at [[1.52521573 1.70982674]]^T\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we'll use the plotting function and specify custom starting points and plotting ranges\n",
    "plot_grad_descent(f1, f1_grad_exact, gradient_descent,\n",
    "                  xrange=(2, 3), yrange=(2, 4),\n",
    "                  start_x=3, start_y=3, lr=0.005\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** The last two tests should be run after the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>Gradient Descent</pre></strong> passed! ðŸ’¯</p><p><strong><pre style='display: inline;'>Gradient Descent - 1</pre> message:</strong> Gradient Descent Trajectory Test Passed</p><p><strong><pre style='display: inline;'>Gradient Descent - 2</pre> message:</strong> Gradient Descent Minimum Location Test Passed</p><p><strong><pre style='display: inline;'>Gradient Descent - 3</pre> message:</strong> Gradient Descent Minimum Value Test Passed</p>"
      ],
      "text/plain": [
       "Gradient Descent results: All test cases passed!\n",
       "Gradient Descent - 1 message: Gradient Descent Trajectory Test Passed\n",
       "Gradient Descent - 2 message: Gradient Descent Minimum Location Test Passed\n",
       "Gradient Descent - 3 message: Gradient Descent Minimum Value Test Passed"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Gradient Descent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.b - Choosing Good Initializations (2 Points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we'll use the plotting function and specify custom starting points and plotting ranges\n",
    "# For F2 \n",
    "f2_start_x = 1.25\n",
    "f2_start_y = -0.75\n",
    "f2_lr = 0.0025\n",
    "f2_n_steps = 100\n",
    "\n",
    "plot_grad_descent(f2, f2_grad_exact, gradient_descent,\n",
    "                  xrange=(-1, 1.5), yrange=(-1, 1.25),\n",
    "                  start_x=f2_start_x, start_y=f2_start_y, lr=f2_lr, n_steps=f2_n_steps, silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For F3 \n",
    "f3_start_x = 1.8\n",
    "f3_start_y = 2.2\n",
    "f3_lr = 0.001\n",
    "f3_n_steps = 10000\n",
    "\n",
    "plot_grad_descent(f3, f3_grad_exact, gradient_descent,\n",
    "                  xrange=(-3, 2), yrange=(-1.5, 2.75),\n",
    "                  start_x=f3_start_x, start_y=f3_start_y, lr=f3_lr, n_steps=f3_n_steps, silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3.c - Failure to Converge (2 Points)\n",
    "Find an example of diverging behaviour and describe three ways that we can encourage convergence in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1_start_x = 3.2\n",
    "f1_start_y = -1.6\n",
    "f1_lr = 1\n",
    "f1_n_steps = 100\n",
    "\n",
    "plot_grad_descent(f1, f1_grad_exact, gradient_descent,\n",
    "                  xrange=(-10, 10), yrange=(-10, 10),\n",
    "                  start_x=f1_start_x, start_y=f1_start_y, lr=f1_lr, n_steps=f1_n_steps, silent=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "The graph above shows a convergence problem for our gradient descent algorithm with the imposed parameters. The value keeps oscillating and growing rather than getting closer and converging to the minimum. Moreover, if we take a higher number of steps, the IDE returns the following problems: \n",
    "\n",
    "* **RuntimeWarning: overflow encountered in matmul return float(x.T @ B @ x - x.T @ x + a.T @ x - b.T @ x)**\n",
    "\n",
    "* **RuntimeWarning: invalid value encountered in subtract return float(x.T @ B @ x - x.T @ x + a.T @ x - b.T @ x)**\n",
    "\n",
    "* **RuntimeWarning: invalid value encountered in matmul return float(x.T @ B @ x - x.T @ x + a.T @ x - b.T @ x)**\n",
    "\n",
    "In order to ensure convergence in practice, the following conditions should be met as far as possible: \n",
    "\n",
    "* **1. Find a relevant starting point.** To do so, we can try several starting points and see how they behave in relation to the graph and our model and parameters.\n",
    "\n",
    "* **2. Find a relevant learning rate which must be positive otherwise we change the problem.** Indeed, instead of having a descending gradient, we will have an ascending gradient, which is not suitable for finding a minimum. A low learning rate will theoretically allow our gradient descent to converge, but it will be slow and we must ensure that we have a sufficient number of steps to converge to the minimum. On the contrary, a high learning rate may fail to converge, or even diverge. Alternatively, a non-fixed learning rate that varies over time can be proposed.\n",
    "\n",
    "* **3. Find a relevant number of steps.** We can take a large number of steps and reduce them until we find a \"low\" but suitable value to ensure convergence.\n",
    "\n",
    "Finally, we can also propose **a second stopping condition** in addition to the number of steps, such as **a minimum epsilon value that the gradient should seek to reach**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---\n",
    "## Part 2 - Automatic Differentation (11 Points)\n",
    "\n",
    "In the previous part you saw how you can implement gradient descent to optimize functions by using either approximate or analytical gradients. Luckily for us, there are frameworks which implement derivatives for most functions we might typically care about, and which allow us to differentiate through arbitrary compositions of these functions by using **Automatic Differentiation** (autodiff). Indeed, you may already have encountered frameworks such as PyTorch, TensorFlow or Jax which have robust autodiff implementations.\n",
    "\n",
    "In this part we'll demonstrate the power of autodiff through the [autograd](https://github.com/HIPS/autograd) library which provides a clean interface for automatically differentiating over numpy functions. Let's start by taking a look at the syntax for computing gradients in autograd:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14085257 1.94414724 0.79917082 1.60023341]\n",
      "[0.14085257 1.94414724 0.79917082 1.60023341]\n"
     ]
    }
   ],
   "source": [
    "from autograd import grad \n",
    "import autograd.numpy as np # Autograd wraps numpy to support automatic differentiation\n",
    "# Note that particularly niche numpy functions may not be supported by autograd\n",
    "\n",
    "# Consider the sum of squares function\n",
    "def xsq(x): \n",
    "    return np.sum(x**2)\n",
    "\n",
    "# We know the gradient of this! \n",
    "def our_grad_of_xsq(x):\n",
    "    return 2*x\n",
    "\n",
    "x = np.random.rand(4)\n",
    "\n",
    "# We can wrap functions with grad to get the gradient function\n",
    "autograd_grad_of_xsq = grad(xsq, 0) # 0 => want the gradient with respect to the first argument\n",
    "\n",
    "# Evaluate gradients at x and check that they're the same\n",
    "print(autograd_grad_of_xsq(x))\n",
    "print(our_grad_of_xsq(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 4 - Squared Distances and Automatic Differentiation\n",
    "Although we can see that autograd is perfectly capable of computing derivatives by itself, there may be instances where the derivative of a non-elementary function is analytically *more efficient* than the composition of the gradients of its components. This means that we are better off telling autograd to use our derivate when it performs automatic differentation (sometimes we might also use esoteric functions which don't even have an existing derivate, in which case we are forced to provide one).\n",
    "\n",
    "#### Question 4.a - Forward Pass of the Squared Distances function (1 Point)\n",
    "In particular, we'll consider the gradient of \n",
    "$$ s = \\vec{p}^T \\mathbf{D} \\vec{q}, $$\n",
    "with respect to $\\vec{z}$, where $\\vec{p}$ and $\\vec{q}$ are constants, and $\\mathbf{D}$ is the matrix of squared distances between elements of $\\vec{z}$:\n",
    "$$ D_{ij} = \\exp(-(z_i - z_j)^2). $$\n",
    "\n",
    "Get warmed up by implementing the the function ```sq_dist_fwd(p,q,x)``` which computes $\\vec{s}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "np.random.seed(0)\n",
    "\n",
    "# Naive solution\n",
    "p = np.random.rand(4)\n",
    "q = np.random.rand(4) \n",
    "\n",
    "def sq_dist_fwd(p,q,x):\n",
    "    \"\"\" Compute the inner product of p and q, projected through a matrix consisting of the \n",
    "        squared distance between elements of a variable x. All vectors are length x.shape[0].\n",
    "        To be compatible with autograd, we need to avoid using assignments on array indices \n",
    "    \"\"\"\n",
    "    \n",
    "    N = x.shape[0]\n",
    "    assert N % 2 == 0 # We expect even numbers of elements\n",
    "    assert x.shape[0] == p.shape[0] == q.shape[0]\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculating D with a loop over the matrix using array indices\n",
    "    \"\"\"\n",
    "    \n",
    "    #I initialize the matix of squared distancess between elements of x (z)\n",
    "    #D = np.zeros((x.shape[0], x.shape[0])) \n",
    "    \n",
    "    #Loop over the matrix to compute each element\n",
    "    #for i in range(N):\n",
    "        #for j in range(N):\n",
    "            #D[i][j] = np.exp(-(x[i]-x[j])**2)\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculating D without using array indices to be compatible with autograd\n",
    "    \"\"\"\n",
    "    \n",
    "    #Here z directly represents x whereas at the end of the coursework it will represent a function of x\n",
    "    z = np.array([x]) \n",
    "    \n",
    "    #Broadcasting stretches both arrays \n",
    "    D = np.exp(-(z - z.T)**2) \n",
    "    \n",
    "    #Definition of s\n",
    "    out = p.T @ D @ q\n",
    "    \n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.278563706100499"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the function for random values\n",
    "x = np.random.rand(4)\n",
    "sq_dist_fwd(p,q,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>Q4.a Squared Distance Function</pre></strong> passed! ðŸŒˆ</p><p><strong><pre style='display: inline;'>Q4.a Squared Distance Function - 1</pre> message:</strong> Squared Distance Function Output Shape Test Passed</p>"
      ],
      "text/plain": [
       "Q4.a Squared Distance Function results: All test cases passed!\n",
       "Q4.a Squared Distance Function - 1 message: Squared Distance Function Output Shape Test Passed"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Q4.a Squared Distance Function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.b - Analytical Derivate of Squared Distances (2 Points)\n",
    "In order to override autograd's gradient for our squared distance function, we need to derive it ourselves - compute the derivate:\n",
    "$$\\frac{\\partial \\vec{s}}{\\partial \\vec{z}} =\\sum_{i j} a_i b_j \\frac{\\partial D_{i j}}{\\partial \\vec{z}}, $$\n",
    "with respect to one element of $\\vec{z}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\vec{s}}{\\partial \\vec{z_n}} =\n",
    "\\begin{cases}\n",
    "2\\sum_{i j} a_i b_j (z_j - z_i) exp(-(z_i-z_j)^2) & \\text{if $n = i$} \\\\\n",
    "2\\sum_{i j} a_i b_j (z_i - z_j) exp(-(z_i-z_j)^2) & \\text{if $n = j$} \\\\\n",
    "0 & \\text{otherwise ($n \\neq i,j)$} \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Question 4.c - Implement the Derivative (2 Points)\n",
    "With the analytical derivate in hand, complete the ```sq_dist_grad_elem(a, b, x, z)``` function which computes the gradient with respect to the $n^{th}$ dimension of $\\vec{z}$ and the corresponding function ```sq_dist_grad``` which computes the gradient vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implement your analytical gradients here\n",
    "\n",
    "# Gradient w.r.t nth element of z\n",
    "# NOTE - you can ignore this function if you prefer to vectorize your implementation\n",
    "def sq_dist_grad_elem(p, q, z, n):\n",
    "    \n",
    "    #Initializing our dimensions and sum\n",
    "    shape = z.shape[0]\n",
    "    grad_sk = 0\n",
    "    \n",
    "    #Looping over the matrix to compute each element depending on the three cases presented above\n",
    "    for i in range(shape):\n",
    "        for j in range(shape):\n",
    "            if i == n :\n",
    "                grad_sk = grad_sk + p[i] * q[j] * (2 * (z[j]-z[i]) * np.exp(-(z[i]-z[j])**2))\n",
    "            elif j == n : \n",
    "                grad_sk = grad_sk + p[i] * q[j] * (2 * (z[i]-z[j]) * np.exp(-(z[i]-z[j])**2))\n",
    "            else : \n",
    "                grad_sk = grad_sk + 0\n",
    "    \n",
    "    return grad_sk\n",
    "\n",
    "# Gradient w.r.t the whole vector z\n",
    "def sq_dist_grad(p, q, z):\n",
    "    \n",
    "    #Initializing our dimensions and array\n",
    "    shape = z.shape[0]\n",
    "    grad_s = np.zeros((shape))\n",
    "    \n",
    "    #Computing all elements of our gradient of s\n",
    "    for n in range(shape):\n",
    "        grad_s[n] = sq_dist_grad_elem(p,q,z,n)\n",
    "        \n",
    "    return grad_s    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>Q4.c Squared Distance Function Gradients</pre></strong> passed! ðŸ’¯</p><p><strong><pre style='display: inline;'>Q4.c Squared Distance Function Gradients - 1</pre> message:</strong> Squared Distance Gradient Function Shape Test Passed</p>"
      ],
      "text/plain": [
       "Q4.c Squared Distance Function Gradients results: All test cases passed!\n",
       "Q4.c Squared Distance Function Gradients - 1 message: Squared Distance Gradient Function Shape Test Passed"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Q4.c Squared Distance Function Gradients\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of the gradient generated with the analytical derivate  : [-0.79128396 -0.902273    1.10949745  0.58405951]\n",
      "Output of the gradient generated with autograd : [-0.79128396 -0.902273    1.10949745  0.58405951]\n",
      "Do we have the same results between the two methods? [ True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# (optional) It is a good idea to check the output of your gradient\n",
    "# function against the one generated by autograd\n",
    "\n",
    "#Selecting random values\n",
    "p = np.random.rand(4)\n",
    "q = np.random.rand(4)\n",
    "z = np.random.rand(4)\n",
    "\n",
    "#Our functions\n",
    "autograd_grad_of_xsq = grad(sq_dist_fwd, 2)(p,q,z) # 2 => want the gradient with respect to the 3rd argument\n",
    "hand_grad = sq_dist_grad(p, q, z)\n",
    "\n",
    "print('Output of the gradient generated with the analytical derivate  :', hand_grad)\n",
    "print('Output of the gradient generated with autograd :', autograd_grad_of_xsq)      \n",
    "print('Do we have the same results between the two methods?', np.round(hand_grad,5) == np.round(autograd_grad_of_xsq,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.d - Automatic Differentiation (2 Points)\n",
    "\n",
    "Armed with our superior gradient function for the sum of squared distances, let's tell autograd to use it, and convince ourselves that all our hardwork was worthwhile!\n",
    "\n",
    "First, let's compare memory usage to check whether our implementation actually requires less memory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours:  peak memory: 151.41 MiB, increment: 0.23 MiB\n",
      "Theirs: peak memory: 153.57 MiB, increment: 2.15 MiB\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler\n",
    "p,q,z = np.random.randn(200), np.random.randn(200), np.random.randn(200)\n",
    "print('Ours: ', end=' ') #Analytical\n",
    "%memit sq_dist_grad(p,q,z)\n",
    "print('Theirs:', end=' ') #Autograd\n",
    "%memit grad(sq_dist_fwd, 2)(p,q,z) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that our implementation of the gradient function requires considerably less memory than the one autograd provides by using autodiff. \n",
    "\n",
    "Now let's tell autograd to use our analytically derived gradient function when computing autodiff for a more complicated function:\n",
    "$$ \\vec{y} = \\vec{s} = \\vec{p}^T \\mathbf{D}(\\vec{z}) \\vec{q}, \\quad \\text{and} \\quad \\vec{z} = 3\\sin{x}+5$$\n",
    "\n",
    "We'll start by revisiting our toy example of $x^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are constructing the computational graph\n",
      "The gradient function has been stored in the graph \n",
      "\n",
      "We are auto differentiating\n",
      "gradient in was 1.0, answer in was 14.0\n",
      "\n",
      "Gradient out:  [2. 4. 6.]\n"
     ]
    }
   ],
   "source": [
    "from autograd.extend import primitive, defvjp\n",
    "# First we'll consider the x squared example again\n",
    "\n",
    "@primitive # This tells autograd we will define the gradient ourselves\n",
    "def xsq(x): \n",
    "    return np.sum(x**2)\n",
    "\n",
    "# Here's an example of how to define a custom backward pass gradient function\n",
    "def xsq_vjp(ans, x):\n",
    "    \"\"\" This should return a function which takes the gradient (g) of the SUBSEQUENT function\n",
    "        and combines it with the gradient of the function we're differentiating \n",
    "        (i.e. propagating the accumulated gradient backwards through the graph)\n",
    "    \"\"\"\n",
    "    print('We are constructing the computational graph')\n",
    "\n",
    "    def xsq_vjp_inner(g):\n",
    "        print('We are auto differentiating')\n",
    "        print(f'gradient in was {g}, answer in was {ans}\\n')\n",
    "        return 2*x*g \n",
    "    \n",
    "    print('The gradient function has been stored in the graph \\n')\n",
    "    return xsq_vjp_inner\n",
    "\n",
    "defvjp(xsq, xsq_vjp)\n",
    "\n",
    "print('Gradient out: ', grad(xsq)(np.array([1., 2., 3.])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply the same idea to our squared distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial \n",
    "# We'll overwrite the naive solution with a primitive\n",
    "# to make life easier let's fix p and q with \"partial\"\n",
    "p,q,z = np.random.randn(4), np.random.randn(4), np.random.randn(4)\n",
    "sq_dist_fwd_wrapped = partial(sq_dist_fwd, p, q)\n",
    "sq_dist_grad_wrapped = partial(sq_dist_grad, p, q)\n",
    "\n",
    "@primitive # Tell autograd we'll use a custom gradient for sq_dist\n",
    "def sq_dist(z):\n",
    "    # Function returns the squared distance with p,q fixed\n",
    "    \n",
    "    return sq_dist_fwd_wrapped(z) \n",
    "\n",
    "def sq_dist_vjp(ans, z): \n",
    "    # Return a function which takes the gradient of the SUBSEQUENT function\n",
    "    # and combines it with the gradient of sq_dist\n",
    "    \n",
    "    def sq_dist_vjp_inner(g):\n",
    "        \n",
    "        return sq_dist_grad_wrapped(z)*g #Chain rule\n",
    "    \n",
    "    return sq_dist_vjp_inner\n",
    "\n",
    "defvjp(sq_dist, sq_dist_vjp) # Assign backward gradient sq_dist_vjp to sq_dist function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>Q4.d Squared Distance Autodiff</pre></strong> passed! ðŸŒŸ</p><p><strong><pre style='display: inline;'>Q4.d Squared Distance Autodiff - 1</pre> message:</strong> Squared Distance Autodiff Value Test Passed</p>"
      ],
      "text/plain": [
       "Q4.d Squared Distance Autodiff results: All test cases passed!\n",
       "Q4.d Squared Distance Autodiff - 1 message: Squared Distance Autodiff Value Test Passed"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"Q4.d Squared Distance Autodiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4.e - Understanding Autodiff (4 Points)\n",
    "Now that we've seen how to define custom gradients for autodiff, let's double check our understanding:\n",
    "1. Draw the computational graph for the ```complete_function(x)```, defined below\n",
    "2. Estimate the Memory and Time complexity of the autodiff gradient calculation, and compare this to ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21285313, -2.3276132 , -0.18500383,  2.29914173])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consider the function\n",
    "x = np.random.rand(4)\n",
    "z = np.sin(x)*3 + 5\n",
    "y = sq_dist(z)\n",
    "\n",
    "# we can compute the gradient of y with respect to x using autograd\n",
    "def complete_function(x):\n",
    "    z = np.sin(x)*3 + 5\n",
    "    return sq_dist(z) # This will now use our gradient function!\n",
    "\n",
    "grad(complete_function)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Title: Computational Graph Pages: 1 -->\n",
       "<svg width=\"254pt\" height=\"468pt\"\n",
       " viewBox=\"0.00 0.00 254.00 468.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 464)\">\n",
       "<title>Computational Graph</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-464 250,-464 250,4 -4,4\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-10\" font-family=\"Times New Roman,serif\" font-size=\"20.00\">Computational Graph for Q4</text>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster_0</title>\n",
       "<polygon fill=\"pink\" stroke=\"pink\" points=\"55,-305 55,-452 191,-452 191,-305 55,-305\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-436.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">First Function</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster_1</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"lightblue\" points=\"29,-86 29,-233 217,-233 217,-86 29,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-217.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Squared Distance Function</text>\n",
       "</g>\n",
       "<!-- x -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>x</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"123\" cy=\"-403\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-399.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">x</text>\n",
       "</g>\n",
       "<!-- 3 * sin(x) + 5 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>3 * sin(x) + 5</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"123\" cy=\"-331\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-327.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">3 * sin(x) + 5</text>\n",
       "</g>\n",
       "<!-- x&#45;&gt;3 * sin(x) + 5 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>x&#45;&gt;3 * sin(x) + 5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-384.7C123,-376.98 123,-367.71 123,-359.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-359.1 123,-349.1 119.5,-359.1 126.5,-359.1\"/>\n",
       "</g>\n",
       "<!-- z -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>z</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"123\" cy=\"-259\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-255.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">z</text>\n",
       "</g>\n",
       "<!-- 3 * sin(x) + 5&#45;&gt;z -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>3 * sin(x) + 5&#45;&gt;z</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-312.7C123,-304.98 123,-295.71 123,-287.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-287.1 123,-277.1 119.5,-287.1 126.5,-287.1\"/>\n",
       "</g>\n",
       "<!-- D = exp(&#45; (z &#45; z.T) Â²) -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>D = exp(&#45; (z &#45; z.T) Â²)</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"123\" cy=\"-184\" rx=\"85.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-180.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">D = exp(&#45; (z &#45; z.T) Â²)</text>\n",
       "</g>\n",
       "<!-- p.T @ D @ q -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>p.T @ D @ q</title>\n",
       "<ellipse fill=\"white\" stroke=\"white\" cx=\"123\" cy=\"-112\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"123\" y=\"-108.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">p.T @ D @ q</text>\n",
       "</g>\n",
       "<!-- D = exp(&#45; (z &#45; z.T) Â²)&#45;&gt;p.T @ D @ q -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>D = exp(&#45; (z &#45; z.T) Â²)&#45;&gt;p.T @ D @ q</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-165.7C123,-157.98 123,-148.71 123,-140.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-140.1 123,-130.1 119.5,-140.1 126.5,-140.1\"/>\n",
       "</g>\n",
       "<!-- z&#45;&gt;D = exp(&#45; (z &#45; z.T) Â²) -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>z&#45;&gt;D = exp(&#45; (z &#45; z.T) Â²)</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M123,-240.7C123,-232.25 123,-221.87 123,-212.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.5,-212.18 123,-202.18 119.5,-212.18 126.5,-212.18\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x2712b8b6550>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Question 4.e.i - Create a (rough) computational graph for the function\n",
    "   NOTE the following:\n",
    "    1. You do not have to use graphviz (example given here) - you can \n",
    "       use tools such as https://draw.io or https://www.lucidchart.com\n",
    "       and embed the results into this notebook (or upload them and provide\n",
    "       a link) - just be sure to check that they appear in the LabTS output\n",
    "       PDF\n",
    "    2. If you want to use Graphviz, you will need to install it on your machine\n",
    "       (from https://www.graphviz.org/download) or work on one of the DoC machines. \n",
    "\"\"\"\n",
    "\n",
    "from graphviz import Digraph\n",
    "comp_graph = Digraph('Computational Graph') # Create Digraph object\n",
    "\n",
    "with comp_graph.subgraph(name='cluster_0') as c:\n",
    "    c.attr(style='filled', color='pink', label='First Function')\n",
    "    c.node_attr.update(style='filled', color='white')\n",
    "    c.edges([('x', '3 * sin(x) + 5')])\n",
    "\n",
    "with comp_graph.subgraph(name='cluster_1') as c:\n",
    "    c.attr(style='filled', color='lightblue', label='Squared Distance Function')\n",
    "    c.node_attr.update(style='filled', color='white')\n",
    "    c.edges([('D = exp(- (z - z.T) Â²)', 'p.T @ D @ q')])\n",
    "    \n",
    "comp_graph.node('z')\n",
    "comp_graph.edge('3 * sin(x) + 5', 'z')\n",
    "comp_graph.edge('z', 'D = exp(- (z - z.T) Â²)')\n",
    "\n",
    "comp_graph.attr(label=r'\\n\\nComputational Graph for Q4')\n",
    "comp_graph.attr(fontsize='20')\n",
    "comp_graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.e.ii - Complexity Answer:**\n",
    "\n",
    "Suppose we have a **vector z of size N** and that **p,q** are also **vectors of size N**. Hence,\n",
    "\n",
    "* **Ours** _(sq_dist_grad)_**:** \n",
    "\n",
    "    * **Time :** $O(N^{2})$. I have 3 'for' loops but our matrix only calculates 2 values while the rest is null/0. For instance, for a gradient matrix with columns of size N, we'll have about N-2 null elements on its columns. \n",
    "    \n",
    "    * **Memory :** $O(N)$ . We're only storing our matrix 'grad_s' and as is implied above, for each column we'll have approximately 2 values different from 0. \n",
    "\n",
    "* **Theirs** _(grad(sq_dist_fwd)_**:** \n",
    "    \n",
    "    * **Time :** $O(N^{2})$. We have time = nb_output * evaluation_time = $1 * NÂ²$.\n",
    "    \n",
    "    * **Memory :** $O(2*N^{2})$ or approximately $O(N^{2})$. We mainly consider the matrix product pDq. However, p and q are vectors and not square matrices. Thus, instead of having $O(N^{3})$ we only consider the size of the matrix D\n",
    "    \n",
    "Interesting GitHub repo : https://github.com/HIPS/autograd/issues/219"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "---\n",
    "## Submission\n",
    "Once you have completed all questions and re-ran all tests, simply push your final notebook to gitlab. You'll want to go to the [LabTS Exercise](https://teaching.doc.ic.ac.uk/labts/lab_exercises/2223/exercises/732/exercise_summary) and check that there are no strange bugs on our end - note that the test results you see on LabTS should be identical to the tests provided in this notebook; of course, we also have other tests which will be run for marking purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1. Function 1 Minima Check results: All test cases passed!\n",
       "1. Function 1 Minima Check - 1 message: F1 Minimum Check (with minimum) Test Passed\n",
       "\n",
       "2.a Method of Finite Differences results: All test cases passed!\n",
       "2.a Method of Finite Differences - 1 message: Finite Differences on f1 Test Passed\n",
       "2.a Method of Finite Differences - 2 message: Finite Differences on f2 Test Passed\n",
       "\n",
       "Gradient Descent results: All test cases passed!\n",
       "Gradient Descent - 1 message: Gradient Descent Trajectory Test Passed\n",
       "Gradient Descent - 2 message: Gradient Descent Minimum Location Test Passed\n",
       "Gradient Descent - 3 message: Gradient Descent Minimum Value Test Passed\n",
       "\n",
       "Gradient Descent Initialization results: All test cases passed!\n",
       "\n",
       "Q2.b.i Gradients of the Functions - f1 results: All test cases passed!\n",
       "Q2.b.i Gradients of the Functions - f1 - 1 message: Exact Gradients of f1 Test Passed\n",
       "\n",
       "Q2.b.ii Gradients of the Functions - f2 results: All test cases passed!\n",
       "Q2.b.ii Gradients of the Functions - f2 - 1 message: Exact Gradients of f2 Test Passed\n",
       "\n",
       "Q2.b.iii Gradients of the Functions - f3 results: All test cases passed!\n",
       "Q2.b.iii Gradients of the Functions - f3 - 1 message: Exact Gradients of f2 Test Passed\n",
       "\n",
       "Q4.a Squared Distance Function results: All test cases passed!\n",
       "Q4.a Squared Distance Function - 1 message: Squared Distance Function Output Shape Test Passed\n",
       "\n",
       "Q4.c Squared Distance Function Gradients results: All test cases passed!\n",
       "Q4.c Squared Distance Function Gradients - 1 message: Squared Distance Gradient Function Shape Test Passed\n",
       "\n",
       "Q4.d Squared Distance Autodiff results: All test cases passed!\n",
       "Q4.d Squared Distance Autodiff - 1 message: Squared Distance Autodiff Value Test Passed"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "1. Function 1 Minima Check": {
     "name": "1. Function 1 Minima Check",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # Check with minimum\n>>> f1_check_minimum(B, a, b)\nTrue",
         "failure_message": "F1 Minimum Check (with minimum) Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "F1 Minimum Check (with minimum) Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "2.a Method of Finite Differences": {
     "name": "2.a Method of Finite Differences",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> B = np.array([[4, -2], [-2, 4]])\n>>> a = np.array([[0], [1]])\n>>> b = np.array([[-2], [1]])\n>>> def f1(x):\n...     return float(x.T @ B @ x - x.T @ x + a.T @ x - b.T @ x)\n>>> dummy_input = np.array([[2.5], [3.5]])\n>>> output = grad_fd(f1, dummy_input)\n>>> \n>>> target_output = np.array([[3.00003, 11.00003]])\n>>> np.isclose(output, target_output, atol=1e-3).all()\nTrue",
         "failure_message": "Finite Differences on f1 Test Failed",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Finite Differences on f1 Test Passed"
        },
        {
         "code": ">>> B = np.array([[4, -2], [-2, 4]])\n>>> a = np.array([[0], [1]])\n>>> b = np.array([[-2], [1]])\n>>> def f2(x):\n...     return float(np.cos((x - b).T @ (x - b)) + (x - a).T @ B @ (x - a))\n>>> dummy_input = np.array([[2.5], [3.5]])\n>>> output = grad_fd(f2, dummy_input)\n>>> \n>>> target_output = np.array([[1.18572957, 5.10321673]])\n>>> np.isclose(output, target_output, atol=1e-3).all()\nTrue",
         "failure_message": "Finite Differences on f2 Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Finite Differences on f2 Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Gradient Descent": {
     "name": "Gradient Descent",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> c = np.array([[4], [5]])\n>>> dummy_fn = lambda x: float(c.T @ x)\n>>> dummy_fn_grad = lambda x: c.T\n>>> dummy_start_x, dummy_start_y = 1.0, 2.0\n>>> \n>>> trajectory, minimum_loc, minimum_value = gradient_descent(dummy_fn, dummy_fn_grad, start_x=dummy_start_x, start_y=dummy_start_y, lr=0.01, n_steps=5, silent=True)\n>>> \n>>> target_trajectory = [np.array([[1], [2]]), np.array([[0.96], [1.95]]), np.array([[0.92], [1.9]]),\n...                     np.array([[0.88], [1.85]]), np.array([[0.84], [1.8]]), np.array([[0.8], [1.75]])]\n>>> \n>>> np.array([np.isclose(target.flatten(), output.flatten(), atol=1e-3) for target, output in zip(target_trajectory, trajectory)]).all()\nTrue",
         "failure_message": "Gradient Descent Trajectory Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Gradient Descent Trajectory Test Passed"
        },
        {
         "code": ">>> c = np.array([[4], [5]])\n>>> dummy_fn = lambda x: float(c.T @ x)\n>>> dummy_fn_grad = lambda x: c.T\n>>> dummy_start_x, dummy_start_y = 1.0, 2.0\n>>> \n>>> trajectory, minimum_loc, minimum_value = gradient_descent(dummy_fn, dummy_fn_grad, start_x=dummy_start_x, start_y=dummy_start_y, lr=0.01, n_steps=5, silent=True)\n>>> target_minimum_loc = np.array([[0.8], [1.75]])\n>>> np.isclose(target_minimum_loc, minimum_loc, atol=1e-3).all()\nTrue",
         "failure_message": "Gradient Descent Minimum Location Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Gradient Descent Minimum Location Test Passed"
        },
        {
         "code": ">>> c = np.array([[4], [5]])\n>>> dummy_fn = lambda x: float(c.T @ x)\n>>> dummy_fn_grad = lambda x: c.T\n>>> dummy_start_x, dummy_start_y = 1.0, 2.0\n>>> \n>>> trajectory, minimum_loc, minimum_value = gradient_descent(dummy_fn, dummy_fn_grad, start_x=dummy_start_x, start_y=dummy_start_y, lr=0.01, n_steps=5, silent=True)\n>>> target_minimum_value = 11.949999999999998\n>>> np.isclose(target_minimum_value, minimum_value, atol=1e-3)\nTrue",
         "failure_message": "Gradient Descent Minimum Value Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Gradient Descent Minimum Value Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Gradient Descent Initialization": {
     "name": "Gradient Descent Initialization",
     "points": 2,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q2.b.i Gradients of the Functions - f1": {
     "name": "Q2.b.i Gradients of the Functions - f1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> B = np.array([[4, -2], [-2, 4]])\n>>> a = np.array([[0], [1]])\n>>> b = np.array([[-2], [1]])\n>>> dummy_input = np.array([[2.5], [3.5]])\n>>> output = f1_grad_exact(dummy_input)\n>>> \n>>> target_output = np.array([[3.0, 11.0]])\n>>> np.isclose(output, target_output, atol=1e-3).all()\nTrue",
         "failure_message": "Exact Gradients of f1 Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Exact Gradients of f1 Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q2.b.ii Gradients of the Functions - f2": {
     "name": "Q2.b.ii Gradients of the Functions - f2",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> B = np.array([[4, -2], [-2, 4]])\n>>> a = np.array([[0], [1]])\n>>> b = np.array([[-2], [1]])\n>>> dummy_input = np.array([[2.5], [3.5]])\n>>> output = f2_grad_exact(dummy_input)\n>>> \n>>> target_output = np.array([[1.1858, 5.1032]])\n>>> np.isclose(output, target_output, atol=1e-3).all()\nTrue",
         "failure_message": "Exact Gradients of f2 Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Exact Gradients of f2 Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q2.b.iii Gradients of the Functions - f3": {
     "name": "Q2.b.iii Gradients of the Functions - f3",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> B = np.array([[4, -2], [-2, 4]])\n>>> a = np.array([[0], [1]])\n>>> b = np.array([[-2], [1]])\n>>> dummy_input = np.array([[2.5], [3.5]])\n>>> output = f3_grad_exact(dummy_input)\n>>> \n>>> target_output = np.array([[0.02699379, 0.03779876]])\n>>> np.isclose(output, target_output, atol=1e-3).all()\nTrue",
         "failure_message": "Exact Gradients of f2 Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Exact Gradients of f2 Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q4.a Squared Distance Function": {
     "name": "Q4.a Squared Distance Function",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p = np.random.rand(4)\n>>> q = np.random.rand(4)\n>>> x = np.random.rand(4)\n>>> () == sq_dist_fwd(p, q, x).shape\nTrue",
         "failure_message": "Squared Distance Function Output Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Squared Distance Function Output Shape Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q4.c Squared Distance Function Gradients": {
     "name": "Q4.c Squared Distance Function Gradients",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> p = np.random.rand(4)\n>>> q = np.random.rand(4)\n>>> x = np.random.rand(4)\n>>> (4,) == sq_dist_grad(p,q,x).shape \nTrue",
         "failure_message": "Squared Distance Gradient Function Shape Test Failed",
         "hidden": false,
         "locked": false,
         "points": 0,
         "success_message": "Squared Distance Gradient Function Shape Test Passed"
        },
        {
         "code": ">>> #! think I prefer to test for us of \"grad\" from autograd, rather than do memory test\n>>> # 1. this is more robust ; 2. we can them provide demo of the memory use as proof of utility   \n>>> # \"\"\" # BEGIN TEST CONFIG\n>>> # name: test_sq_dist_grad_memory\n>>> # points: 2\n>>> # hidden: true \n>>> # success_message: 'Squared Distance Gradient Memory Test Passed'\n>>> # failure_message: 'Squared Distance Gradient Memory Test Failed'\n>>> # \"\"\" # END TEST CONFIG\n>>> # %%capture result\n>>> # %load_ext memory_profiler\n>>> # a,b,x = np.random.randn(100), np.random.randn(100), np.random.randn(100)\n>>> # %memit manual_grad_vec(a,b,x)\n>>> # %%capture result2\n>>> # %memit grad(sq_dist_fwd, 2)(a,b,x) \n>>> # get_mem_usage = lambda x: float(str(x)[12:str(x).find('MiB')])\n>>> # 3*get_mem_usage(result) < get_mem_usage(result2)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q4.d Squared Distance Autodiff": {
     "name": "Q4.d Squared Distance Autodiff",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> our_grad = grad(sq_dist, 0)(z) # This is calling our custom gradient function\n>>> their_grad = grad(sq_dist_fwd, 2)(p,q,z) # This is uses slow gradient primitives\n>>> np.allclose(our_grad, their_grad, atol=1e-3)\nTrue",
         "failure_message": "Squared Distance Autodiff Value Test Failed",
         "hidden": false,
         "locked": false,
         "points": 2,
         "success_message": "Squared Distance Autodiff Value Test Passed"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "3c89a9bb9c0cb0f9eadf088879d08118d7275393e9f46779256c83918de27aa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
